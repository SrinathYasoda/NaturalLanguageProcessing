{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import os\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datapath='G:\\\\JOBIFY\\\\movie_reviews\\\\movie_reviews'\n",
    "\n",
    "# train=[]\n",
    "# test=[]\n",
    "# for category in ['pos','neg']:\n",
    "#     path=os.path.join(datapath,category)\n",
    "#     for fname in sorted(os.listdir(path)):\n",
    "#         if fname.endswith('.txt'):\n",
    "#             with open(os.path.join(path,fname),encoding='utf8') as f:\n",
    "#                 train.append(f.read())\n",
    "#             test.append(0 if category=='neg' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('G:\\\\JOBIFY\\\\ClassNotes\\\\NLP\\\\train.tsv.zip', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseId       int64\n",
      "SentenceId     int64\n",
      "Phrase        object\n",
      "Sentiment      int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.dtypes)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token=RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv=CountVectorizer(stop_words='english',ngram_range=(1,1),tokenizer=token.tokenize)\n",
    "text_counts=cv.fit_transform(dataset['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(text_counts,dataset['Sentiment'],test_size=0.3,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB=MultinomialNB()\n",
    "MNB.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB accuracy score (1,1) ngram is 60.23%\n"
     ]
    }
   ],
   "source": [
    "predict=MNB.predict(X_test)\n",
    "MNB_AccuracyScore=accuracy_score(predict,Y_test)\n",
    "print('MNB accuracy score (1,1) ngram is {:04.2f}'.format(MNB_AccuracyScore*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB accuracy score (2,2) ngram is 60.02%\n"
     ]
    }
   ],
   "source": [
    "#trying with different ngrams\n",
    "#trying (2,2) gram\n",
    "cv=CountVectorizer(stop_words='english',ngram_range=(2,2),tokenizer=token.tokenize)\n",
    "text_counts=cv.fit_transform(dataset['Phrase'])\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(text_counts,dataset['Sentiment'],test_size=0.3,random_state=5)\n",
    "\n",
    "MNB=MultinomialNB()\n",
    "MNB.fit(X_train,Y_train)\n",
    "\n",
    "predict=MNB.predict(X_test)\n",
    "MNB_AccuracyScore=accuracy_score(predict,Y_test)\n",
    "print('MNB accuracy score (2,2) ngram is {:04.2f}'.format(MNB_AccuracyScore*100)+'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB accuracy score (3,3) ngram is 58.83%\n"
     ]
    }
   ],
   "source": [
    "#trying (3,3) ngram\n",
    "cv=CountVectorizer(stop_words='english',ngram_range=(3,3),tokenizer=token.tokenize)\n",
    "text_counts=cv.fit_transform(dataset['Phrase'])\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(text_counts,dataset['Sentiment'],test_size=0.3,random_state=5)\n",
    "\n",
    "MNB=MultinomialNB()\n",
    "MNB.fit(X_train,Y_train)\n",
    "\n",
    "predict=MNB.predict(X_test)\n",
    "MNB_AccuracyScore=accuracy_score(predict,Y_test)\n",
    "print('MNB accuracy score (3,3) ngram is {:04.2f}'.format(MNB_AccuracyScore*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Among all (1,1) ngram accuracy is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying different Naive Bayes algorithms\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(stop_words='english',ngram_range=(1,1),tokenizer=token.tokenize)\n",
    "text_counts=cv.fit_transform(dataset['Phrase'])\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(text_counts,dataset['Sentiment'],test_size=0.3,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNB accuracy score is 46.80%\n"
     ]
    }
   ],
   "source": [
    "CNB=ComplementNB()\n",
    "CNB.fit(X_train,Y_train)\n",
    "predict=CNB.predict(X_test)\n",
    "CNB_Accuracy_score=accuracy_score(predict,Y_test)\n",
    "print('CNB accuracy score is {:04.2f}'.format(CNB_Accuracy_score*100)+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNB=GaussianNB()\n",
    "# GNB.fit(X_train.todense(),Y_train)\n",
    "\n",
    "\n",
    "# predict=GNB.predict(X_test)\n",
    "# GNB_Accuracy_score=accuracy_score(predict,Y_test)\n",
    "# print('GNB accuracy score is {:04.2f}'.format(GNB_Accuracy_score*100)+'%')\n",
    "\n",
    "# GNB = GaussianNB()\n",
    "# GNB.fit(X_train.todense(), Y_train)\n",
    "# accuracy_score = accuracy_score(CNB.predict(X_test),Y_test)\n",
    "\n",
    "# print('GNB accuracy = ' + str('{:4.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB accuracy = 60.44%\n"
     ]
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, Y_train)\n",
    "accuracy_score_bnb = accuracy_score(BNB.predict(X_test),Y_test)\n",
    "print('BNB accuracy = ' + str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BernouliNB accuary is good amont three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TERM FREQUENCY INVERSE DOCUMENT FREQUENCY\n",
    "# Its a product of Term Frequency and Inverse Document Frequency\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#token=RegexpTokenizer(r'[a-zA-Z0-9]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB accuracy score tfidf is 58.57%\n",
      "CNB accuracy score is 51.31%\n",
      "BNB accuracy = 59.19%\n"
     ]
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "text_token2=tfidf.fit_transform(dataset['Phrase'])\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(text_token2,dataset['Sentiment'],test_size=0.3,random_state=5)\n",
    "\n",
    "#MNB \n",
    "MNB.fit(x_train,y_train)\n",
    "predict=MNB.predict(x_test)\n",
    "MNB_AccuracyScore=accuracy_score(predict,y_test)\n",
    "print('MNB accuracy score tfidf is {:04.2f}'.format(MNB_AccuracyScore*100)+'%')\n",
    "\n",
    "#CNB\n",
    "CNB.fit(x_train,y_train)\n",
    "predict=CNB.predict(x_test)\n",
    "CNB_Accuracy_score=accuracy_score(predict,y_test)\n",
    "print('CNB accuracy score is {:04.2f}'.format(CNB_Accuracy_score*100)+'%')\n",
    "\n",
    "#BNB\n",
    "BNB.fit(x_train, y_train)\n",
    "accuracy_score_bnb = accuracy_score(BNB.predict(x_test),y_test)\n",
    "print('BNB accuracy = ' + str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinath Yasoda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Count Vectorizer Accuracy 63.81%\n",
      "Logistic TFIDF Vectorizer Accuracy 62.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinath Yasoda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## Implementing Non NaiveBayes models such as Logistic, StochasticGradientDescent Classifier and SVM\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# LR=LogisticRegression()\n",
    "# SGDC=SGDClassifier()\n",
    "# SVC=LinearSVC()\n",
    "\n",
    "#LR \n",
    "LR.fit(X_train,Y_train)\n",
    "accuracy_score_LR_CV=accuracy_score(LR.predict(X_test),Y_test)\n",
    "print('Logistic Count Vectorizer Accuracy {:4.2f}'.format(accuracy_score_LR_CV*100)+'%')\n",
    "\n",
    "LR.fit(x_train,y_train)\n",
    "accuracy_score_LR_TFIDF=accuracy_score(LR.predict(x_test),y_test)\n",
    "print('Logistic TFIDF Vectorizer Accuracy {:4.2f}'.format(accuracy_score_LR_TFIDF*100)+'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Count Vectorizer Accuracy 60.35%\n",
      "Stochastic TFIDF Vectorizer Accuracy 56.60%\n"
     ]
    }
   ],
   "source": [
    "# SGDC\n",
    "SGDC.fit(X_train,Y_train)\n",
    "accuracy_score_sgdc_CV=accuracy_score(SGDC.predict(X_test),Y_test)\n",
    "print('Stochastic Count Vectorizer Accuracy {:4.2f}'.format(accuracy_score_sgdc_CV*100)+'%')\n",
    "\n",
    "SGDC.fit(x_train,y_train)\n",
    "accuracy_score_sgdc_TFIDF=accuracy_score(SGDC.predict(x_test),y_test)\n",
    "print('Stochastic TFIDF Vectorizer Accuracy {:4.2f}'.format(accuracy_score_sgdc_TFIDF*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupportVM Count Vectorizer Accuracy 62.71%\n",
      "SupportVM TFIDF Vectorizer Accuracy 63.95%\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "SVC.fit(X_train,Y_train)\n",
    "accuracy_score_SVC_CV=accuracy_score(SVC.predict(X_test),Y_test)\n",
    "print('SupportVM Count Vectorizer Accuracy {:4.2f}'.format(accuracy_score_SVC_CV*100)+'%')\n",
    "\n",
    "SVC.fit(x_train,y_train)\n",
    "accuracy_score_SVC_TFIDF=accuracy_score(SVC.predict(x_test),y_test)\n",
    "print('SupportVM TFIDF Vectorizer Accuracy {:4.2f}'.format(accuracy_score_SVC_TFIDF*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
